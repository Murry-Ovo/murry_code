{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV and JSON Creator\n",
    "\n",
    "This Python script will:\n",
    "\n",
    "- Run a sql query against Big Query\n",
    "- Save the results as a dataframe\n",
    "- Exported the dataframe to a CSV or JSON to your local computer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Export Functions\n",
    "\n",
    "The following  creates the functions required to export to csv or to json. \n",
    "\n",
    "The minimal parameters you need to pass through the function is the name of a dataframe/sql code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating functions ---\n",
      "--- Created function 'export_to_csv' ---\n",
      "--- Created function 'export_to_json' ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "\n",
    "##########################\n",
    "### Creating functions ###\n",
    "##########################\n",
    "\n",
    "print(\"--- Creating functions ---\")\n",
    "\n",
    "# Export a dataframe to csv\n",
    "# Pass the sql_code variable through first then optional filname and export path\n",
    "def export_to_csv(sql_variable, filename = 'python csv export', path = 'C:\\\\Python CSV Output\\\\'):\n",
    "    print('-----------------------')\n",
    "    print('Start csv export')\n",
    "    sql_variable = sql_variable\n",
    "    print('- Creating dataframe from sql code')\n",
    "    df = pd.read_gbq(sql_variable,\n",
    "                     project_id = 'data-science-retail',\n",
    "                     dialect    = 'standard')  \n",
    "    filename = filename + '-' + str(dt.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    print('- Filename: '+ filename)\n",
    "    path = path+filename+'.csv'\n",
    "    print('- Save location: ' + path)\n",
    "    df.to_csv(path, index = False, encoding=\"utf8\")\n",
    "    print('- Successfully exported file - '+filename)\n",
    "    print('-----------------------')\n",
    "\n",
    "print(\"--- Created function 'export_to_csv' ---\")   \n",
    "\n",
    "\n",
    "def export_to_json(dataframe, filename = 'python json export', path = 'C:\\\\Python CSV Output\\\\', orient=\"records\", indent=2):\n",
    "    print('-----------------------')\n",
    "    print('Start csv export')\n",
    "    filename = filename + '-' + str(dt.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    print('- Filename: '+ filename)\n",
    "    path = path+filename+'.json'\n",
    "    print('- Save location: ' + path)\n",
    "    orient = orient\n",
    "    print('- json orientation = '+orient)\n",
    "    indent = indent\n",
    "    dataframe.to_json(path, orient=orient, date_format='iso', indent=indent)\n",
    "    print('- Successfully exported json file - '+filename)\n",
    "    print('-----------------------')\n",
    "\n",
    "print(\"--- Created function 'export_to_json' ---\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating SQL variables for each output ---\n",
      "--- Created SQL variables ---\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "### Creating SQL Code Variables ###\n",
    "###################################\n",
    "\n",
    "print('--- Creating SQL variables for each output ---')\n",
    "\n",
    "# Main SQL code block \n",
    "# Create a CTE for each different output file \n",
    "\n",
    "main_code = \"\"\"\n",
    "WITH\n",
    "Master_Table_With_True_Comms_Type AS\n",
    "      (\n",
    "      SELECT \n",
    "            *\n",
    "            ,'POST' AS Comms_Type_1\n",
    "            ,CASE\n",
    "              WHEN Has_PSR_Audio_Comms = 1                 THEN 'PSR Audio Comms'\n",
    "              WHEN Has_PSR_Braille_Comms = 1               THEN 'PSR Braille Comms'\n",
    "              WHEN Has_PSR_Largeprint_Blackwhite_Comms = 1 THEN 'PSR Large BW Comms'\n",
    "              WHEN Has_PSR_Print_Blackwhite_Comms = 1      THEN 'PSR BW Comms'\n",
    "              WHEN Has_PSR_Largeprint_Comms = 1            THEN 'PSR Largeprint Comms'\n",
    "              WHEN Has_PSR_Print_Comms = 1                 THEN 'PSR Regular Print Comms' \n",
    "              ELSE 'Regular Comms'\n",
    "             END Comms_Type_2  \n",
    "\n",
    "      FROM\n",
    "            `data-science-retail.switching_compensation.phase_3_full_data_snapshot_20201110`\n",
    "\n",
    "      WHERE\n",
    "            Account_No IN (SELECT * FROM `data-science-retail.switching_compensation.phase_3_email_bounces`)\n",
    "      )      \n",
    "\n",
    ",Staging AS\n",
    "(\n",
    "SELECT\n",
    "      Account_No\n",
    "     ,Account_Status\n",
    "     ,Account_Supply_End_Date\n",
    "     ,Retailer\n",
    "     ,Payment_Method_Category\n",
    "     ,Current_Billing_System\n",
    "     ,Was_CoS_Switching_Overcharge\n",
    "     ,Was_Renewals_Switching_Overcharge\n",
    "     ,Total_Overcharge\n",
    "     ,Total_Goodwill_Inc_PSR_Bonus\n",
    "     ,Original_Phase1_Goodwill\n",
    "     ,New_Goodwill_Minus_Original\n",
    "     ,Total_Refund_Due\n",
    "     ,Title\n",
    "     ,CASE WHEN First_Name like '__/__/____' THEN NULL ELSE First_Name END AS First_Name\n",
    "     ,Last_Name\n",
    "     ,Has_Tracked_and_Traced_Address\n",
    "     -- Case statements to use track and trace addresses if we have them, otherwise use the Apollo address data\n",
    "     ,CASE WHEN Has_Tracked_and_Traced_Address = 1 THEN UPPER(Tracked_Address_Line_1) ELSE UPPER(REPLACE(Address_Line_1, '?','')) END AS Address_Line_1\t-- Removing odd question marks from address data\n",
    "     ,CASE WHEN Has_Tracked_and_Traced_Address = 1 THEN UPPER(Tracked_Address_Line_2) ELSE UPPER(Address_Line_2) END AS Address_Line_2\t\n",
    "     ,CASE WHEN Has_Tracked_and_Traced_Address = 1 THEN UPPER(Tracked_Address_Line_3) ELSE NULL                  END AS Address_Line_3\n",
    "     ,CASE WHEN Has_Tracked_and_Traced_Address = 1 THEN UPPER(Tracked_Address_Line_4) ELSE UPPER(Town)           END AS Town\t\n",
    "     ,CASE WHEN Has_Tracked_and_Traced_Address = 1 THEN UPPER(Tracked_postcode)       ELSE UPPER(Postcode)       END AS Postcode\n",
    "     ,Is_PSR\n",
    "     ,Has_PSR_Comms_Pref\n",
    "     ,Has_PSR_Audio_Comms\n",
    "     ,Has_PSR_Braille_Comms\n",
    "     ,Has_PSR_Print_Comms\n",
    "     ,Has_PSR_Print_Blackwhite_Comms\n",
    "     ,Has_PSR_Largeprint_Comms\n",
    "     ,Has_PSR_Largeprint_Blackwhite_Comms\n",
    "     -- Comms Type 1 = EMAIL or POST\n",
    "     ,Comms_Type_1\n",
    "     -- Comms Type 2 = PSR variant\n",
    "     ,Comms_Type_2\n",
    "     ,Comms_Scenario\n",
    "\n",
    "FROM \n",
    "      Master_Table_With_True_Comms_Type     \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "## Combining the main code with an individual SELECT * FROM xxxxx for each CTE you want to export, this will be\n",
    "\n",
    "sc1_paym = main_code+\"\"\"\n",
    "SELECT * FROM Staging WHERE  Comms_Scenario = 1 AND Payment_Method_Category = 'PAYM'\n",
    "\"\"\"\n",
    "\n",
    "sc2_paym = main_code+\"\"\"\n",
    "SELECT * FROM Staging WHERE  Comms_Scenario = 2 AND Payment_Method_Category = 'PAYM'\n",
    "\"\"\"\n",
    "\n",
    "sc3_payg = main_code+\"\"\"\n",
    "SELECT * FROM Staging WHERE  Comms_Scenario = 3 AND Payment_Method_Category = 'PAYG'\n",
    "\"\"\"\n",
    "\n",
    "sc3_paym = main_code+\"\"\"\n",
    "SELECT * FROM Staging WHERE  Comms_Scenario = 3 AND Payment_Method_Category = 'PAYM'\n",
    "\"\"\"\n",
    "\n",
    "sc4_payg = main_code+\"\"\"\n",
    "SELECT * FROM Staging WHERE  Comms_Scenario = 4 AND Payment_Method_Category = 'PAYG'\n",
    "\"\"\"\n",
    "\n",
    "sc4_paym = main_code+\"\"\"\n",
    "SELECT * FROM Staging WHERE  Comms_Scenario = 4 AND Payment_Method_Category = 'PAYM'\n",
    "\"\"\"\n",
    "\n",
    "## If you get an error here try printing out the combined script (in a different cell) and troubleshoot in Big Query\n",
    "## e.g:\n",
    "## print(select_from_cte_1_code)\n",
    "\n",
    "\n",
    "print(\"--- Created SQL variables ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating dataframes for each output ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 254/254 [00:00<00:00, 452.74rows/s]\n",
      "Downloading: 100%|██████████| 14/14 [00:00<00:00, 86.41rows/s]\n",
      "Downloading: 100%|██████████| 19/19 [00:00<00:00, 80.85rows/s]\n",
      "Downloading: 100%|██████████| 54/54 [00:00<00:00, 158.81rows/s]\n",
      "Downloading: 100%|██████████| 85/85 [00:00<00:00, 326.90rows/s]\n",
      "Downloading: 100%|██████████| 25/25 [00:00<00:00, 101.62rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Created Dataframes ---\n",
      "--- Starting CSV / JSON export ---\n",
      "-----------------------\n",
      "Start csv export\n",
      "- Creating dataframe from sql code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 254/254 [00:00<00:00, 762.72rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filename: sc1_paym-20201201-103146\n",
      "- Save location: C:\\Python CSV Output\\sc1_paym-20201201-103146.csv\n",
      "- Successfully exported file - sc1_paym-20201201-103146\n",
      "-----------------------\n",
      "-----------------------\n",
      "Start csv export\n",
      "- Creating dataframe from sql code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 14/14 [00:00<00:00, 63.63rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filename: sc2_paym-20201201-103148\n",
      "- Save location: C:\\Python CSV Output\\sc2_paym-20201201-103148.csv\n",
      "- Successfully exported file - sc2_paym-20201201-103148\n",
      "-----------------------\n",
      "-----------------------\n",
      "Start csv export\n",
      "- Creating dataframe from sql code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 19/19 [00:00<00:00, 76.61rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filename: sc3_payg-20201201-103149\n",
      "- Save location: C:\\Python CSV Output\\sc3_payg-20201201-103149.csv\n",
      "- Successfully exported file - sc3_payg-20201201-103149\n",
      "-----------------------\n",
      "-----------------------\n",
      "Start csv export\n",
      "- Creating dataframe from sql code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 54/54 [00:00<00:00, 227.83rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filename: sc3_paym-20201201-103151\n",
      "- Save location: C:\\Python CSV Output\\sc3_paym-20201201-103151.csv\n",
      "- Successfully exported file - sc3_paym-20201201-103151\n",
      "-----------------------\n",
      "-----------------------\n",
      "Start csv export\n",
      "- Creating dataframe from sql code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 85/85 [00:00<00:00, 333.31rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filename: sc4_payg-20201201-103152\n",
      "- Save location: C:\\Python CSV Output\\sc4_payg-20201201-103152.csv\n",
      "- Successfully exported file - sc4_payg-20201201-103152\n",
      "-----------------------\n",
      "-----------------------\n",
      "Start csv export\n",
      "- Creating dataframe from sql code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 25/25 [00:00<00:00, 124.37rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filename: sc4_paym-20201201-103154\n",
      "- Save location: C:\\Python CSV Output\\sc4_paym-20201201-103154.csv\n",
      "- Successfully exported file - sc4_paym-20201201-103154\n",
      "-----------------------\n",
      "--- Exports Completed ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###########################\n",
    "### creating dataframes ###\n",
    "###########################\n",
    "\n",
    "print('--- Creating dataframes for each output ---')\n",
    "\n",
    "## Saving the results of SQL code as a dataframe, \n",
    "## Copy and paste this and just change the dataframe and SQL code variable each time\n",
    "\n",
    "sc1_paym_df = pd.read_gbq(sc1_paym,\n",
    "                                   project_id = 'data-science-retail',\n",
    "                                   dialect    = 'standard')\n",
    "\n",
    "sc2_paym_df = pd.read_gbq(sc2_paym,\n",
    "                                   project_id = 'data-science-retail',\n",
    "                                   dialect    = 'standard')\n",
    "\n",
    "sc3_payg_df = pd.read_gbq(sc3_payg,\n",
    "                                   project_id = 'data-science-retail',\n",
    "                                   dialect    = 'standard')\n",
    "\n",
    "sc3_paym_df = pd.read_gbq(sc3_paym,\n",
    "                                   project_id = 'data-science-retail',\n",
    "                                   dialect    = 'standard')\n",
    "\n",
    "sc4_payg_df = pd.read_gbq(sc4_payg,\n",
    "                                   project_id = 'data-science-retail',\n",
    "                                   dialect    = 'standard')\n",
    "\n",
    "sc4_paym_df = pd.read_gbq(sc4_paym,\n",
    "                                   project_id = 'data-science-retail',\n",
    "                                   dialect    = 'standard')\n",
    "\n",
    "print(\"--- Created Dataframes ---\")\n",
    "\n",
    "################################################\n",
    "### Saving Each Dataframes To A Separate CSV ###\n",
    "################################################\n",
    "\n",
    "print('--- Starting CSV / JSON export ---')\n",
    "\n",
    "## This saves the results of the code to the specified path\n",
    "## You can change the filename by replacing the 'Sample_Filename_1'\n",
    "\n",
    "export_to_csv(sql_variable = sc1_paym\n",
    "              ,filename = 'sc1_paym')\n",
    "\n",
    "export_to_csv(sql_variable = sc2_paym\n",
    "              ,filename = 'sc2_paym')\n",
    "\n",
    "export_to_csv(sql_variable = sc3_payg\n",
    "              ,filename = 'sc3_payg')\n",
    "\n",
    "export_to_csv(sql_variable = sc3_paym\n",
    "              ,filename = 'sc3_paym')\n",
    "\n",
    "export_to_csv(sql_variable = sc4_payg\n",
    "              ,filename = 'sc4_payg')\n",
    "\n",
    "export_to_csv(sql_variable = sc4_paym\n",
    "              ,filename = 'sc4_paym')\n",
    "\n",
    "print('--- Exports Completed ---')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
